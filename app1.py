# app.py
# =========================================================
# Webapp Streamlit: T·ªëi ∆∞u chi·∫øn l∆∞·ª£c giao d·ªãch c·ªï phi·∫øu ng√¢n h√†ng (VN)
# 4 b∆∞·ªõc: L·ªçc -> T·ªëi ∆∞u t·ª∑ tr·ªçng (SA/GA) -> Grid WMA Top% -> Ensemble + lu·∫≠t VN + Backtest
# =========================================================

import streamlit as st
import pandas as pd
import numpy as np
from datetime import date
import random
import logging

from scipy.optimize import dual_annealing
from deap import base, creator, tools, algorithms
from vnstock import Quote

from ta.trend import wma_indicator
from joblib import Parallel, delayed

from backtesting import Backtest, Strategy

# =========================================================
# PH·∫¶N 1. H√ÄM TI·ªÜN √çCH / LOGIC CHO 4 B∆Ø·ªöC
# =========================================================

# ---------- B∆∞·ªõc 1: L·ªçc c·ªï phi·∫øu ----------
def fetch_price_history(ticker, start_date, end_date):
    """
    L·∫•y d·ªØ li·ªáu gi√° ƒë√≥ng c·ª≠a ng√†y cho 1 m√£.
    Tr·∫£ v·ªÅ DataFrame index=Date, c·ªôt 'Close'.
    N·∫øu g·ªçi API th·∫•t b·∫°i (v√≠ d·ª• b·ªã ch·∫∑n tr√™n Cloud) -> tr·∫£ v·ªÅ None thay v√¨ l√†m app crash.
    """
    try:
        q = Quote(source='vci', symbol=ticker)
        df = q.history(start=start_date, end=end_date, interval='1D')
    except Exception as e:
        # log nh·∫π ƒë·ªÉ debug, nh∆∞ng ƒë·ª´ng kill app
        print(f"[WARN] fetch_price_history({ticker}) l·ªói khi g·ªçi API: {e}")
        return None

    if df is None or df.empty:
        print(f"[WARN] fetch_price_history({ticker}): API tr·∫£ v·ªÅ r·ªóng.")
        return None

    df = df[['time', 'close']].rename(columns={'time': 'Date', 'close': 'Close'})
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.set_index('Date').sort_index()
    return df



def screen_bank_stocks(
    bank_list,
    start_date='2015-01-01',
    end_date='2023-12-31',
    max_missing_ratio=0.4
):
    """
    Qu√©t ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu t·ª´ng m√£ bank.
    N·∫øu API b·ªã ch·∫∑n => df = None => m√£ ƒë√≥ s·∫Ω b·ªã ƒë√°nh d·∫•u NO DATA
    App v·∫´n ti·∫øp t·ª•c ch·∫°y.
    """
    results = []
    price_panel = {}

    total_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days + 1

    for ticker in bank_list:
        df = fetch_price_history(ticker, start_date, end_date)

        if df is None or df.empty:
            results.append({
                "Ticker": ticker,
                "Status": "NO DATA",
                "MissingRatio": 1.0,
                "Ndays": 0
            })
            continue

        available_days = df.shape[0]
        missing_ratio = 1 - (available_days / total_days)

        status = "OK" if missing_ratio <= max_missing_ratio else "DROP"

        results.append({
            "Ticker": ticker,
            "Status": status,
            "MissingRatio": round(missing_ratio, 4),
            "Ndays": available_days
        })

        if status == "OK":
            price_panel[ticker] = df['Close']

    summary_df = pd.DataFrame(results)

    if len(price_panel) > 0:
        merged_prices = pd.DataFrame(price_panel)
    else:
        merged_prices = pd.DataFrame()

    return summary_df, merged_prices



# ---------- B∆∞·ªõc 2: T·ªëi ∆∞u t·ª∑ tr·ªçng ----------
def get_return_cov_matrix(price_df):
    """
    price_df: m·ªói c·ªôt l√† 1 m√£ c·ªï phi·∫øu, m·ªói d√≤ng l√† gi√° ƒë√≥ng c·ª≠a theo ng√†y.
    Tr·∫£ v·ªÅ l·ª£i su·∫•t k·ª≥ v·ªçng nƒÉm h√≥a v√† ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai nƒÉm h√≥a.
    """
    returns = price_df.pct_change().dropna()
    mean_returns = returns.mean() * 252          # annualized expected return
    cov_matrix   = returns.cov() * 252           # annualized covariance
    return mean_returns, cov_matrix


def portfolio_performance(weights, mean_returns, cov_matrix, rf=0.035):
    """
    T√≠nh Return, Volatility, Sharpe Ratio c·ªßa m·ªôt vector tr·ªçng s·ªë.
    """
    port_ret = np.dot(weights, mean_returns)
    port_vol = np.sqrt(weights.T @ cov_matrix @ weights)
    sharpe = (port_ret - rf) / port_vol if port_vol > 0 else -999
    return port_ret, port_vol, sharpe


def normalize_weights(w_raw: np.ndarray):
    """
    Chu·∫©n h√≥a vector tr·ªçng s·ªë v·ªÅ:
    - kh√¥ng √¢m
    - t·ªïng = 1
    """
    w = np.clip(w_raw, 0, None)  # √©p √¢m -> 0
    s = w.sum()
    if s == 0:
        w[:] = 1.0 / len(w)
    else:
        w = w / s
    return w


def sharpe_ratio(weights, mean_returns, cov_matrix, rf=0.035):
    """
    T√≠nh Sharpe Ratio c·ªßa m·ªôt vector tr·ªçng s·ªë (ƒë√£ chu·∫©n h√≥a).
    """
    w = normalize_weights(np.array(weights, dtype=float))
    port_ret = np.dot(w, mean_returns)
    port_vol = np.sqrt(w.T @ cov_matrix @ w)
    if port_vol <= 0:
        return -999
    return (port_ret - rf) / port_vol


def negative_sharpe_ratio(weights, mean_returns, cov_matrix, rf=0.035):
    """
    H√†m m·ª•c ti√™u cho b·ªô t·ªëi ∆∞u: MINIMIZE(-Sharpe) ƒë·ªÉ 't·ªëi ƒëa Sharpe'.
    """
    return -sharpe_ratio(weights, mean_returns, cov_matrix, rf=rf)


def optimize_weights_sa(mean_returns, cov_matrix, rf=0.035):
    """
    T·ªëi ∆∞u tr·ªçng s·ªë b·∫±ng Simulated Annealing (dual_annealing).
    r√†ng bu·ªôc: m·ªói weight trong [0,1], sau ƒë√≥ chu·∫©n h√≥a l·∫°i t·ªïng=1.
    """
    num_assets = len(mean_returns)
    bounds = [(0, 1) for _ in range(num_assets)]

    def objective(w):
        return negative_sharpe_ratio(w, mean_returns.values, cov_matrix.values, rf=rf)

    result_sa = dual_annealing(objective, bounds=bounds)
    optimal_weights_sa = normalize_weights(result_sa.x)

    ret, vol, sh = portfolio_performance(
        optimal_weights_sa,
        mean_returns.values,
        cov_matrix.values,
        rf=rf
    )

    return {
        "weights": optimal_weights_sa,
        "return": ret,
        "vol": vol,
        "sharpe": sh,
        "method": "SA"
    }


def optimize_weights_ga(mean_returns, cov_matrix, rf=0.035,
                        population_size=100, ngen=50,
                        cxpb=0.7, mutpb=0.2):
    """
    T·ªëi ∆∞u tr·ªçng s·ªë b·∫±ng Genetic Algorithm (DEAP) ‚Äì rerun-safe cho Streamlit.
    """
    num_assets = len(mean_returns)

    # RERUN-SAFE: ch·ªâ t·∫°o class 1 l·∫ßn
    try:
        creator.FitnessMin
    except AttributeError:
        creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
    try:
        creator.Individual
    except AttributeError:
        creator.create("Individual", list, fitness=creator.FitnessMin)

    toolbox = base.Toolbox()
    toolbox.register("attr_float", random.uniform, 0, 1)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=num_assets)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)

    def evaluate(individual):
        return (
            negative_sharpe_ratio(
                individual,
                mean_returns.values,
                cov_matrix.values,
                rf=rf
            ),
        )

    toolbox.register("evaluate", evaluate)
    toolbox.register("mate", tools.cxBlend, alpha=0.5)
    toolbox.register("mutate", tools.mutGaussian, mu=0.5, sigma=0.2, indpb=0.2)
    toolbox.register("select", tools.selTournament, tournsize=3)

    population = toolbox.population(n=population_size)

    algorithms.eaSimple(
        population,
        toolbox,
        cxpb=cxpb,
        mutpb=mutpb,
        ngen=ngen,
        verbose=False
    )

    best_ind = tools.selBest(population, k=1)[0]
    optimal_weights_ga = normalize_weights(np.array(best_ind, dtype=float))

    ret, vol, sh = portfolio_performance(
        optimal_weights_ga,
        mean_returns.values,
        cov_matrix.values,
        rf=rf
    )

    return {
        "weights": optimal_weights_ga,
        "return": ret,
        "vol": vol,
        "sharpe": sh,
        "method": "GA"
    }


def pretty_weights_report(tickers, weights_arr):
    return pd.DataFrame({
        "Ticker": tickers,
        "Weight(%)": [round(w*100, 2) for w in weights_arr]
    })


# ---------- B∆∞·ªõc 3: T·ªëi ∆∞u tham s·ªë WMA ----------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def get_stock_data_for_backtesting(ticker, start_date, end_date):
    """
    L·∫•y d·ªØ li·ªáu OHLCV cho backtesting lib.
    Tr·∫£ v·ªÅ DataFrame index=Datetime, c·ªôt ['Open','High','Low','Close','Volume'].
    """
    try:
        q = Quote(source='vci', symbol=ticker)
        data = q.history(start=start_date, end=end_date, interval='1D')

        if data is None or data.empty:
            logging.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu cho m√£ {ticker}")
            return None

        data = data.copy()
        data.rename(columns={
            'open': 'Open',
            'high': 'High',
            'low': 'Low',
            'close': 'Close',
            'volume': 'Volume',
            'time': 'Time'
        }, inplace=True)

        data['Time'] = pd.to_datetime(data['Time'])
        data.set_index('Time', inplace=True)

        data = data[['Open', 'High', 'Low', 'Close', 'Volume']].sort_index()
        data.fillna(method='ffill', inplace=True)

        return data

    except Exception as e:
        logging.error(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu m√£ {ticker}: {e}")
        return None


class MAStrategyWMA(Strategy):
    """
    Chi·∫øn l∆∞·ª£c MA crossover d√πng WMA.
    V√†o l·ªánh khi WMA ng·∫Øn c·∫Øt l√™n WMA d√†i; tho√°t khi c·∫Øt xu·ªëng.
    """
    short_period = 10
    long_period = 50

    def init(self):
        self.ma_short = self.I(
            lambda x: wma_indicator(pd.Series(x), window=int(self.short_period)),
            self.data.Close
        )
        self.ma_long = self.I(
            lambda x: wma_indicator(pd.Series(x), window=int(self.long_period)),
            self.data.Close
        )

    def next(self):
        if self.ma_short[-1] > self.ma_long[-1] and self.ma_short[-2] <= self.ma_long[-2]:
            self.buy()
        elif self.ma_short[-1] < self.ma_long[-1] and self.ma_short[-2] >= self.ma_long[-2]:
            self.position.close()


def run_backtest_wma(short_period, long_period, data_ohlc):
    """
    Ch·∫°y backtest WMA(short,long) tr√™n d·ªØ li·ªáu OHLC.
    Tr·∫£ v·ªÅ Sharpe Ratio. N·∫øu short>=long th√¨ lo·∫°i.
    """
    if short_period >= long_period:
        return -1

    bt = Backtest(
        data_ohlc,
        MAStrategyWMA,
        cash=100_000,
        commission=0.002  # 0.2%
    )

    stats = bt.run(short_period=int(short_period), long_period=int(long_period))
    sharpe = stats.get('Sharpe Ratio', -1)
    return sharpe


def optimize_wma_grid_for_ticker(ticker, train_start, train_end, top_percent=0.1):
    """
    Grid WMA cho 1 m√£:
    - short in [5..45 step 5], long in [51..191 step 10]
    - tr·∫£ v·ªÅ top 10% theo Sharpe
    """
    data_ohlc = get_stock_data_for_backtesting(
        ticker,
        start_date=train_start,
        end_date=train_end
    )
    if data_ohlc is None or data_ohlc.empty:
        return None

    results = []
    for short_p in range(5, 50, 5):
        for long_p in range(51, 200, 10):
            sharpe = run_backtest_wma(short_p, long_p, data_ohlc)
            results.append({
                "Ticker": ticker,
                "MA": "WMA",
                "Short": short_p,
                "Long": long_p,
                "Sharpe": sharpe
            })

    df = pd.DataFrame(results)
    df = df[df['Sharpe'] > -1]
    if df.empty:
        return None

    df_sorted = df.sort_values(by='Sharpe', ascending=False).reset_index(drop=True)
    top_n = max(1, int(len(df_sorted) * top_percent))
    df_top = df_sorted.head(top_n)
    return df_top


# ---------- B∆∞·ªõc 4: Backtest danh m·ª•c cu·ªëi ----------
# ==== THAM S·ªê GIAO D·ªäCH VN D√ôNG CHO DANH M·ª§C CU·ªêI ====
K = 3                         # s·ªë ·ª©ng vi√™n/m√£ ƒë·ªÉ ensemble
VOTE_THRESHOLD = 0.5          # >50% phi·∫øu "mua" th√¨ v√†o l·ªánh
TCOST_BPS = 20                # 20 bps = 0.20%
RF_ANNUAL = 0.035             # l√£i su·∫•t phi r·ªßi ro nƒÉm
PERIODS = 252                 # s·ªë phi√™n/nƒÉm

# R√ÄNG BU·ªòC VN
MIN_HOLD_DAYS = 2             # T+2: gi·ªØ >=2 phi√™n tr∆∞·ªõc khi b√°n
STOP_LOSS_PCT = 0.07          # SL 7%
COOLDOWN_DAYS = 5             # sau SL, cooldown X phi√™n
T2_CASH_DAYS = 2              # ti·ªÅn b√°n v·ªÅ sau 2 phi√™n m·ªõi d√πng l·∫°i


def fetch_prices_multi(tickers, start_date, end_date):
    """
    L·∫•y gi√° ƒë√≥ng c·ª≠a cho nhi·ªÅu m√£, tr·∫£ v·ªÅ DataFrame: index=ng√†y, c·ªôt=ticker.
    """
    price = pd.DataFrame()
    for t in tickers:
        try:
            q = Quote(source='vci', symbol=t)
            df = q.history(start=start_date, end=end_date, interval='1D')
            if df is not None and not df.empty:
                df = df[["time", "close"]].copy()
                df["time"] = pd.to_datetime(df["time"])
                df.set_index("time", inplace=True)
                price = pd.concat(
                    [price, df.rename(columns={"close": t})],
                    axis=1
                )
            else:
                logging.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu cho m√£ {t}")
        except Exception as e:
            logging.error(f"‚ùå L·ªói khi l·∫•y gi√° {t}: {e}")
    return price.sort_index()


def gen_signal_wma_for_price(close_series: pd.Series, short_w: int, long_w: int):
    """
    T·∫°o t√≠n hi·ªáu giao d·ªãch WMA crossover.
    1 = n·∫Øm gi·ªØ; 0 = kh√¥ng n·∫Øm gi·ªØ.
    D·ªãch 1 ng√†y (shift(1)) ƒë·ªÉ tr√°nh nh√¨n t∆∞∆°ng lai.
    """
    short_line = wma_indicator(close_series, window=int(short_w))
    long_line  = wma_indicator(close_series, window=int(long_w))
    raw_sig = (short_line > long_line).astype(int)
    return raw_sig.shift(1).fillna(0).astype(int)


def apply_vn_rules_one(sig_raw: pd.Series,
                       px: pd.Series,
                       min_hold_days: int,
                       stop_loss_pct: float,
                       cooldown_days: int):
    """
    ƒêi·ªÅu ch·ªânh t√≠n hi·ªáu theo lu·∫≠t VN:
    - Gi·ªØ >= min_hold_days phi√™n
    - Stop-loss n·∫øu drawdown <= -stop_loss_pct
    - Sau SL, cooldown X phi√™n kh√¥ng ƒë∆∞·ª£c mua l·∫°i
    """
    sig = sig_raw.copy().astype(int)
    sig_adj = sig.copy()

    in_pos = False
    hold_cnt = 0
    cool_cnt = 0
    entry_price = np.nan

    for i, _ in enumerate(sig.index):
        if cool_cnt > 0:
            sig_adj.iloc[i] = 0
            cool_cnt -= 1
        else:
            sig_adj.iloc[i] = 1 if sig.iloc[i] == 1 else 0

        if not in_pos and sig_adj.iloc[i] == 1:
            in_pos = True
            hold_cnt = 0
            entry_price = px.iloc[i]

        elif in_pos and sig_adj.iloc[i] == 1:
            hold_cnt += 1
            if entry_price and entry_price > 0:
                dd = px.iloc[i] / entry_price - 1.0
                if dd <= -abs(stop_loss_pct):
                    sig_adj.iloc[i] = 0
                    in_pos = False
                    hold_cnt = 0
                    cool_cnt = cooldown_days
                    entry_price = np.nan

        elif in_pos and sig_adj.iloc[i] == 0:
            if hold_cnt < (min_hold_days - 1):
                sig_adj.iloc[i] = 1
                hold_cnt += 1
            else:
                in_pos = False
                hold_cnt = 0
                entry_price = np.nan

        if not in_pos and sig_adj.iloc[i] == 0:
            hold_cnt = 0

    return sig_adj.astype(int)


def build_portfolio_nav(price_df: pd.DataFrame,
                        wma_params_by_ticker: dict,
                        weights_by_ticker: dict,
                        tcost_bps: float,
                        min_hold_days: int,
                        stop_loss_pct: float,
                        cooldown_days: int,
                        t2_cash_days: int):
    """
    (D√πng khi m·ªói m√£ ch·ªâ c√≥ 1 b·ªô WMA). ·ªû app n√†y ta d√πng ensemble nhi·ªÅu b·ªô n√™n d√πng h√†m d∆∞·ªõi.
    H√†m n√†y v·∫´n gi·ªØ l·∫°i n·∫øu b·∫°n c·∫ßn tham kh·∫£o.
    """
    tickers = [
        tk for tk in wma_params_by_ticker.keys()
        if tk in price_df.columns and weights_by_ticker.get(tk, 0) > 0
    ]
    if len(tickers) == 0:
        raise RuntimeError("Kh√¥ng c√≥ m√£ h·ª£p l·ªá (kh√¥ng c√≥ tham s·ªë WMA ho·∫∑c weight > 0).")

    # 1. T√≠n hi·ªáu WMA c∆° b·∫£n
    raw_signals = {}
    for tk in tickers:
        close_series = price_df[tk].dropna()
        params = wma_params_by_ticker[tk]
        sig_raw = gen_signal_wma_for_price(
            close_series,
            short_w=params["short"],
            long_w=params["long"]
        )
        raw_signals[tk] = sig_raw

    # 2. √Åp lu·∫≠t VN
    adj_signals = {}
    for tk in tickers:
        px = price_df[tk].reindex(raw_signals[tk].index).fillna(method='ffill')
        adj_signals[tk] = apply_vn_rules_one(
            sig_raw=raw_signals[tk],
            px=px,
            min_hold_days=min_hold_days,
            stop_loss_pct=stop_loss_pct,
            cooldown_days=cooldown_days
        )

    # 3. Chu·∫©n b·ªã k·∫øt h·ª£p danh m·ª•c + T+2 ti·ªÅn
    idx_union = sorted(set().union(*[s.index for s in adj_signals.values()]))
    idx_union = pd.to_datetime(idx_union)

    weights_mat  = pd.DataFrame(0.0, index=idx_union, columns=tickers)
    signals_mat  = pd.DataFrame(0,   index=idx_union, columns=tickers)
    returns_mat  = pd.DataFrame(0.0, index=idx_union, columns=tickers)
    costs_mat    = pd.DataFrame(0.0, index=idx_union, columns=tickers)

    for tk in tickers:
        w_fixed = weights_by_ticker.get(tk, 0.0)
        px = price_df[tk].reindex(idx_union).fillna(method='ffill')
        sig = adj_signals[tk].reindex(idx_union).fillna(0).astype(int)

        ret = px.pct_change().fillna(0.0)
        turn = sig.diff().abs().fillna(0.0)
        cost = turn * (tcost_bps/10000.0)

        weights_mat[tk] = float(w_fixed)
        signals_mat[tk] = sig
        returns_mat[tk] = ret
        costs_mat[tk]   = cost

    sell_events = (signals_mat.diff() == -1).astype(int)

    blocked_weight = pd.Series(0.0, index=idx_union)
    kernel = np.ones(int(t2_cash_days), dtype=float)
    for tk in tickers:
        w_i = float(weights_mat[tk].iloc[0]) if len(weights_mat[tk]) else 0.0
        seq = sell_events[tk].fillna(0).astype(float).to_numpy() * w_i
        conv = np.convolve(seq, kernel, mode='full')[:len(seq)]
        blocked_weight = blocked_weight.add(pd.Series(conv, index=idx_union), fill_value=0.0)
    blocked_weight = blocked_weight.clip(0.0, 1.0)

    active_weight = (weights_mat * signals_mat).sum(axis=1)
    capacity = (1.0 - blocked_weight).clip(0.0, 1.0)
    scale = pd.Series(1.0, index=idx_union)
    mask = active_weight > 1e-12
    scale.loc[mask] = np.minimum(1.0, (capacity.loc[mask] / active_weight.loc[mask]).astype(float))

    eff_weights = (weights_mat * signals_mat).mul(scale, axis=0)

    per_stock_pnl = eff_weights * (signals_mat * returns_mat - costs_mat)
    port_ret = per_stock_pnl.sum(axis=1).rename("port_ret")
    nav_series = (1 + port_ret).cumprod()
    nav_df = nav_series.to_frame(name="NAV")

    return nav_df, port_ret, {}


def sharpe_annual(daily_ret: pd.Series, rf_annual=RF_ANNUAL, periods=PERIODS):
    if len(daily_ret) == 0 or daily_ret.std() == 0:
        return np.nan
    er = daily_ret.mean()*periods - rf_annual
    vol = daily_ret.std()*np.sqrt(periods)
    return er/vol if vol != 0 else np.nan


def cagr_from_nav(nav: pd.Series, periods=PERIODS):
    if len(nav) < 2 or nav.iloc[0] <= 0:
        return np.nan
    total_return = nav.iloc[-1] / nav.iloc[0]
    years = len(nav) / periods
    return total_return**(1/years) - 1 if years > 0 else np.nan


def max_drawdown(nav: pd.Series):
    if len(nav) == 0:
        return np.nan
    roll_max = nav.cummax()
    dd = nav/roll_max - 1.0
    return dd.min()


def slice_series(s: pd.Series, start: str, end: str):
    if s.empty:
        return s
    return s.loc[(s.index >= pd.to_datetime(start)) & (s.index <= pd.to_datetime(end))]


def build_portfolio_from_ensemble(
    wma_results_by_ticker: dict,
    weights_by_ticker: dict,
    train_start_str: str,
    train_end_str: str,
    test_start_str: str,
    test_end_str: str,
    vote_threshold: float = VOTE_THRESHOLD,
    top_k: int = K,
    tcost_bps: float = TCOST_BPS,
    min_hold_days: int = MIN_HOLD_DAYS,
    stop_loss_pct: float = STOP_LOSS_PCT,
    cooldown_days: int = COOLDOWN_DAYS,
    t2_cash_days: int = T2_CASH_DAYS
):
    """
    Ensemble top-K b·ªô WMA t·ªët nh·∫•t c·ªßa t·ª´ng m√£ (t·ª´ Tab 3), √°p lu·∫≠t VN, gh√©p danh m·ª•c theo tr·ªçng s·ªë (Tab 2),
    x·ª≠ l√Ω T+2 ti·ªÅn, r·ªìi tr·∫£ v·ªÅ NAV + metrics Train/Test.
    """

    # 1) Tickers h·ª£p l·ªá
    usable_tickers = []
    for tk, w in weights_by_ticker.items():
        if w > 0 and (tk in wma_results_by_ticker) and (wma_results_by_ticker[tk] is not None) and (not wma_results_by_ticker[tk].empty):
            usable_tickers.append(tk)
    usable_tickers = sorted(list(set(usable_tickers)))
    if not usable_tickers:
        raise RuntimeError("Kh√¥ng c√≥ m√£ h·ª£p l·ªá ƒë·ªÉ ensemble (c·∫ßn weight>0 v√† c√≥ k·∫øt qu·∫£ WMA ·ªü B∆∞·ªõc 3).")

    # 2) T·∫£i gi√° Train‚ÜíTest
    price_df = fetch_prices_multi(usable_tickers, start_date=train_start_str, end_date=test_end_str)
    if price_df is None or price_df.empty:
        raise RuntimeError("Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu gi√° cho danh m·ª•c.")

    # 3) Ensemble vote tr√™n t·ª´ng m√£ b·∫±ng top-K Sharpe
    base_signals = {}
    picked_rows = []
    for tk in usable_tickers:
        df_top = wma_results_by_ticker[tk].copy()

        if "Sharpe Ratio" in df_top.columns:
            df_top = df_top.sort_values("Sharpe Ratio", ascending=False)
            sharp_col = "Sharpe Ratio"
        else:
            df_top = df_top.sort_values("Sharpe", ascending=False)
            sharp_col = "Sharpe"

        df_top = df_top.head(int(max(1, top_k)))

        px = price_df[tk].dropna()
        if px.empty:
            continue

        sig_list = []
        for _, r in df_top.iterrows():
            sp = int(r["Short"]); lp = int(r["Long"])
            s = gen_signal_wma_for_price(px, sp, lp)
            sig_list.append(s.reindex(px.index).fillna(0).astype(int))
            picked_rows.append([tk, "WMA", sp, lp, float(r[sharp_col])])

        if sig_list:
            mat = pd.concat(sig_list, axis=1)
            ens = (mat.mean(axis=1) > float(vote_threshold)).astype(int)
            base_signals[tk] = ens.reindex(px.index).fillna(0).astype(int)

    if not base_signals:
        raise RuntimeError("Kh√¥ng t·∫°o ƒë∆∞·ª£c t√≠n hi·ªáu ensemble cho b·∫•t k·ª≥ m√£ n√†o.")

    # 4) √Åp lu·∫≠t VN
    adj_signals = {}
    for tk, sig in base_signals.items():
        px = price_df[tk].reindex(sig.index).fillna(method='ffill')
        adj = apply_vn_rules_one(
            sig_raw=sig,
            px=px,
            min_hold_days=min_hold_days,
            stop_loss_pct=stop_loss_pct,
            cooldown_days=cooldown_days
        )
        adj_signals[tk] = adj

    # 5) T+2 ti·ªÅn + chi ph√≠
    idx_union = sorted(set().union(*[sig.index for sig in adj_signals.values()]))
    idx_union = pd.to_datetime(idx_union)

    weights_mat  = pd.DataFrame(0.0, index=idx_union, columns=usable_tickers)
    signals_mat  = pd.DataFrame(0,   index=idx_union, columns=usable_tickers)
    returns_mat  = pd.DataFrame(0.0, index=idx_union, columns=usable_tickers)
    costs_mat    = pd.DataFrame(0.0, index=idx_union, columns=usable_tickers)

    for tk in usable_tickers:
        w_fixed = float(weights_by_ticker.get(tk, 0.0))
        px = price_df[tk].reindex(idx_union).fillna(method='ffill')
        sig = adj_signals[tk].reindex(idx_union).fillna(0).astype(int)

        ret = px.pct_change().fillna(0.0)
        turn = sig.diff().abs().fillna(0.0)
        cost = turn * (tcost_bps/10000.0)

        weights_mat[tk] = w_fixed
        signals_mat[tk] = sig
        returns_mat[tk] = ret
        costs_mat[tk]   = cost

    sell_events = (signals_mat.diff() == -1).astype(int)

    blocked_weight = pd.Series(0.0, index=idx_union)
    kernel = np.ones(int(t2_cash_days), dtype=float)
    for tk in usable_tickers:
        w_i = float(weights_mat[tk].iloc[0]) if len(weights_mat[tk]) else 0.0
        seq = sell_events[tk].fillna(0).astype(float).to_numpy() * w_i
        conv = np.convolve(seq, kernel, mode='full')[:len(seq)]
        blocked_weight = blocked_weight.add(pd.Series(conv, index=idx_union), fill_value=0.0)
    blocked_weight = blocked_weight.clip(0.0, 1.0)

    active_weight = (weights_mat * signals_mat).sum(axis=1)
    capacity = (1.0 - blocked_weight).clip(0.0, 1.0)
    scale = pd.Series(1.0, index=idx_union)
    mask = active_weight > 1e-12
    scale.loc[mask] = np.minimum(1.0, (capacity.loc[mask] / active_weight.loc[mask]).astype(float))

    eff_weights = (weights_mat * signals_mat).mul(scale, axis=0)

    per_stock_pnl = eff_weights * (signals_mat * returns_mat - costs_mat)
    port_ret = per_stock_pnl.sum(axis=1).rename("port_ret")
    nav_df = (1 + port_ret).cumprod().to_frame(name="NAV")

    # 6) Metrics
    metrics_all = {
        "Sharpe": sharpe_annual(port_ret, rf_annual=RF_ANNUAL, periods=PERIODS),
        "CAGR":   cagr_from_nav(nav_df["NAV"], periods=PERIODS),
        "MaxDD":  max_drawdown(nav_df["NAV"])
    }
    pr_train = slice_series(port_ret, train_start_str, train_end_str)
    pr_test  = slice_series(port_ret, test_start_str,  test_end_str)

    def _metrics(seg):
        if seg.empty:
            return {"Sharpe": np.nan, "CAGR": np.nan, "MaxDD": np.nan}
        nv = (1 + seg).cumprod()
        return {
            "Sharpe": sharpe_annual(seg, rf_annual=RF_ANNUAL, periods=PERIODS),
            "CAGR":   cagr_from_nav(nv, periods=PERIODS),
            "MaxDD":  max_drawdown(nv)
        }

    metrics_train = _metrics(pr_train)
    metrics_test  = _metrics(pr_test)

    picked_rows_debug = pd.DataFrame(
        picked_rows, columns=["Ticker","MA","Short","Long","Sharpe"]
    )

    return {
        "nav_df": nav_df,
        "port_ret": port_ret,
        "eff_weights": eff_weights,
        "metrics_all": metrics_all,
        "metrics_train": metrics_train,
        "metrics_test": metrics_test,
        "picked_rows_debug": picked_rows_debug
    }


# =========================================================
# PH·∫¶N 2. UI STREAMLIT (4 TAB)
# =========================================================

st.set_page_config(page_title="Bank Strategy Workflow", layout="wide")
st.title("üìà Quy tr√¨nh t·ªëi ∆∞u chi·∫øn l∆∞·ª£c giao d·ªãch ng√¢n h√†ng Vi·ªát Nam")

# Kh·ªüi t·∫°o session_state
if "selected_stocks" not in st.session_state:
    st.session_state.selected_stocks = []

if "final_weights" not in st.session_state:
    st.session_state.final_weights = {}  # {ticker: weight_float}

if "wma_results" not in st.session_state:
    st.session_state["wma_results"] = {}

# Sidebar c·∫•u h√¨nh chung
st.sidebar.header("C·∫•u h√¨nh chung")
train_start = st.sidebar.date_input("Train start", value=date(2020,1,1))
train_end   = st.sidebar.date_input("Train end",   value=date(2023,12,31))
test_start  = st.sidebar.date_input("Test start",  value=date(2024,1,1))
test_end    = st.sidebar.date_input("Test end",    value=date.today())

# L∆∞u chu·ªói ng√†y ƒë·ªÉ truy·ªÅn h√†m
train_start_str = pd.to_datetime(train_start).strftime("%Y-%m-%d")
train_end_str   = pd.to_datetime(train_end).strftime("%Y-%m-%d")
test_start_str  = pd.to_datetime(test_start).strftime("%Y-%m-%d")
test_end_str    = pd.to_datetime(test_end).strftime("%Y-%m-%d")

rf_annual = st.sidebar.number_input("L√£i su·∫•t phi r·ªßi ro (nƒÉm)", min_value=0.0, max_value=0.2, value=0.035)
tcost_bps = st.sidebar.number_input("Ph√≠ giao d·ªãch (bps)", min_value=0, max_value=200, value=20)

bank_universe_default = [
    'VCB','BID','CTG','TCB','MBB','VPB',
    'STB','TPB','VIB','HDB','LPB','SHB'
]

st.sidebar.caption("M·ªói b∆∞·ªõc: b·∫°n ch·ªçn ‚Üí b·∫•m l∆∞u ‚Üí b∆∞·ªõc sau d√πng d·ªØ li·ªáu ƒë√£ l∆∞u.")

tab1, tab2, tab3, tab4 = st.tabs([
    "1Ô∏è‚É£ L·ªçc c·ªï phi·∫øu",
    "2Ô∏è‚É£ T·ª∑ tr·ªçng danh m·ª•c",
    "3Ô∏è‚É£ T·ªëi ∆∞u tham s·ªë WMA",
    "4Ô∏è‚É£ Ensemble + Backtest"
])

# ============= TAB 1: L·ªåC C·ªî PHI·∫æU =============
with tab1:
    st.header("B∆∞·ªõc 1. L·ªçc c·ªï phi·∫øu ng√¢n h√†ng ƒë·∫ßu v√†o")

    # Hi·ªÉn th·ªã ƒë√£ l∆∞u
    st.markdown("**C√°c m√£ ƒë√£ l∆∞u hi·ªán t·∫°i:**")
    st.write(
        st.session_state.selected_stocks
        if len(st.session_state.selected_stocks) > 0
        else "Ch∆∞a c√≥"
    )

    universe = st.multiselect(
        "Ch·ªçn universe ng√¢n h√†ng ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu",
        options=bank_universe_default,
        default=bank_universe_default
    )

    # n√∫t ch·∫°y l·ªçc
    run_screen = st.button("üìä Ch·∫°y l·ªçc d·ªØ li·ªáu (Screen)")

    # t·∫°o bi·∫øn session_state n·∫øu ch∆∞a c√≥
    if "last_screen_summary" not in st.session_state:
        st.session_state.last_screen_summary = None
    if "last_good_stocks" not in st.session_state:
        st.session_state.last_good_stocks = []

    if run_screen:
        # Giai ƒëo·∫°n train ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu
        train_start_str = train_start.strftime("%Y-%m-%d")
        train_end_str   = train_end.strftime("%Y-%m-%d")

        try:
            summary_df, merged_prices = screen_bank_stocks(
                universe,
                start_date=train_start_str,
                end_date=train_end_str,
                max_missing_ratio=0.4
            )

            st.session_state.last_screen_summary = summary_df

            if summary_df is not None and not summary_df.empty:
                ok_list = summary_df[summary_df["Status"] == "OK"]["Ticker"].tolist()
            else:
                ok_list = []

            st.session_state.last_good_stocks = ok_list

            if len(ok_list) == 0:
                st.warning(
                    "Kh√¥ng m√£ n√†o l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu (c√≥ th·ªÉ server ch·ª©ng kho√°n ch·∫∑n IP Streamlit Cloud). "
                    "B·∫°n v·∫´n ti·∫øp t·ª•c xem lu·ªìng chi·∫øn l∆∞·ª£c ƒë∆∞·ª£c nh∆∞ng d·ªØ li·ªáu th·ª±c t·∫ø c√≥ th·ªÉ c·∫ßn ch·∫°y t·∫°i m√°y local."
                )
            else:
                st.success(f"C√°c m√£ ƒë·∫°t y√™u c·∫ßu d·ªØ li·ªáu: {ok_list}")

        except Exception as e:
            # QUAN TR·ªåNG: n·∫øu vnstock fail (RetryError) th√¨ ta kh√¥ng crash app
            st.error(
                "Kh√¥ng g·ªçi ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ ngu·ªìn ch·ª©ng kho√°n (c√≥ th·ªÉ b·ªã gi·ªõi h·∫°n IP Streamlit Cloud). "
                "H√£y th·ª≠ ch·∫°y l·∫°i tr√™n m√°y local. "
                f"Chi ti·∫øt l·ªói: {e}"
            )

    # Hi·ªÉn th·ªã l·∫°i summary n·∫øu ƒë√£ c√≥ t·ª´ l·∫ßn tr∆∞·ªõc (k·ªÉ c·∫£ sau rerun trang)
    if st.session_state.last_screen_summary is not None:
        st.subheader("Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu c√°c m√£ (l·∫ßn qu√©t g·∫ßn nh·∫•t):")
        st.dataframe(st.session_state.last_screen_summary)

        # Cho ng∆∞·ªùi d√πng ch·ªçn m√£ ƒë·ªÉ l∆∞u cho b∆∞·ªõc sau
        chosen = st.multiselect(
            "Ch·ªçn c√°c m√£ b·∫°n mu·ªën GI·ªÆ l·∫°i cho b∆∞·ªõc sau",
            options=st.session_state.last_good_stocks,
            default=st.session_state.last_good_stocks,
            key="stock_picker_step1"
        )

        if st.button("üíæ L∆∞u danh s√°ch m√£ ƒë√£ ch·ªçn"):
            st.session_state.selected_stocks = chosen
            st.success(f"ƒê√É L∆ØU: {chosen}")
    else:
        st.info("B·∫•m n√∫t 'üìä Ch·∫°y l·ªçc d·ªØ li·ªáu (Screen)' ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu v√† ch·ªçn m√£.")


# ============= TAB 2: T·ªêI ∆ØU T·ª∂ TR·ªåNG =============
with tab2:
    st.header("B∆∞·ªõc 2. ƒê·ªÅ xu·∫•t t·ª∑ tr·ªçng & ch·ªânh tay (d·ª±a tr√™n SA / GA)")

    st.markdown("**Danh s√°ch m√£ ƒë√£ l∆∞u t·ª´ b∆∞·ªõc 1:**")
    st.write(st.session_state.selected_stocks if len(st.session_state.selected_stocks) > 0 else "Ch∆∞a c√≥")

    if len(st.session_state.selected_stocks) == 0:
        st.warning("Ch∆∞a c√≥ m√£ n√†o ƒë∆∞·ª£c l∆∞u ·ªü B∆∞·ªõc 1. Qua tab 1 ƒë·ªÉ l∆∞u tr∆∞·ªõc.")
    else:
        # t·∫£i d·ªØ li·ªáu train cho t·ª´ng m√£ ƒë√£ ch·ªçn
        prices_dict = {}
        for tk in st.session_state.selected_stocks:
            df_price = fetch_price_history(tk, train_start_str, train_end_str)
            if df_price is not None and not df_price.empty:
                prices_dict[tk] = df_price['Close']

        if len(prices_dict) == 0:
            st.error("Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu train cho c√°c m√£ ƒë√£ ch·ªçn.")
        else:
            merged_prices = pd.DataFrame(prices_dict).dropna()

            mean_returns, cov_matrix = get_return_cov_matrix(merged_prices)

            st.subheader("üî• T·ªëi ∆∞u t·ª∑ tr·ªçng b·∫±ng Simulated Annealing (SA)")
            best_sa = optimize_weights_sa(mean_returns, cov_matrix, rf=rf_annual)
            tickers = mean_returns.index.tolist()
            st.write("K·∫øt qu·∫£ SA:")
            st.dataframe(pretty_weights_report(tickers, best_sa["weights"]))
            st.write(
                f"Sharpe={best_sa['sharpe']:.3f} | Return nƒÉm ~ {best_sa['return']*100:.2f}% | "
                f"Vol nƒÉm ~ {best_sa['vol']*100:.2f}%"
            )

            st.subheader("üß¨ (Tu·ª≥ ch·ªçn) T·ªëi ∆∞u b·∫±ng Genetic Algorithm (GA)")
            run_ga = st.checkbox("Ch·∫°y GA ƒë·ªÉ so s√°nh v·ªõi SA (m·∫•t th√™m th·ªùi gian)")
            if run_ga:
                best_ga = optimize_weights_ga(
                    mean_returns,
                    cov_matrix,
                    rf=rf_annual,
                    population_size=100,
                    ngen=50,
                    cxpb=0.7,
                    mutpb=0.2
                )
                st.write("K·∫øt qu·∫£ GA:")
                st.dataframe(pretty_weights_report(tickers, best_ga["weights"]))
                st.write(
                    f"Sharpe={best_ga['sharpe']:.3f} | Return nƒÉm ~ {best_ga['return']*100:.2f}% | "
                    f"Vol nƒÉm ~ {best_ga['vol']*100:.2f}%"
                )
            else:
                best_ga = None

            st.markdown("### ‚úç Ch·ªânh tay t·ª∑ tr·ªçng cu·ªëi c√πng b·∫°n mu·ªën d√πng")
            manual_weights = {}
            total_preview = 0.0

            # ƒë·ªÅ xu·∫•t m·∫∑c ƒë·ªãnh ƒë·ªÉ user ch·ªânh: d√πng SA
            default_weights_source = best_sa["weights"]

            for i, tk in enumerate(tickers):
                default_val_pct = float(default_weights_source[i]*100)
                val_pct = st.number_input(
                    f"T·ª∑ tr·ªçng {tk} (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=round(default_val_pct,2),
                    step=0.5,
                    key=f"weight_input_{tk}"
                )
                manual_weights[tk] = val_pct/100.0
                total_preview += val_pct

            st.write(f"T·ªïng % b·∫°n nh·∫≠p: {round(total_preview,2)}% (m·ª•c ti√™u ~100%)")

            if st.button("üíæ L∆∞u tr·ªçng s·ªë cu·ªëi c√πng ƒë·ªÉ d√πng cho b∆∞·ªõc 4"):
                st.session_state.final_weights = manual_weights
                st.success(f"ƒê√É L∆ØU tr·ªçng s·ªë cu·ªëi: {manual_weights}")


# ============= TAB 3: T·ªêI ∆ØU THAM S·ªê WMA =============
with tab3:
    st.header("B∆∞·ªõc 3. T·ªëi ∆∞u WMA cho t·ª´ng m√£ (grid search) v√† l∆∞u TOP tham s·ªë t·ªët nh·∫•t")

    if len(st.session_state.selected_stocks) == 0:
        st.warning("Ch∆∞a c√≥ m√£ t·ª´ B∆∞·ªõc 1.")
    elif len(st.session_state.final_weights) == 0:
        st.warning("Ch∆∞a c√≥ tr·ªçng s·ªë t·ª´ B∆∞·ªõc 2.")
    else:
        usable_tickers = [
            tk for tk in st.session_state.selected_stocks
            if st.session_state.final_weights.get(tk, 0) > 0
        ]

        st.write("C√°c m√£ s·∫Ω t·ªëi ∆∞u WMA (tr·ªçng s·ªë > 0):", usable_tickers)
        st.write(f"Giai ƒëo·∫°n TRAIN: {train_start_str} ‚Üí {train_end_str}")

        run_opt = st.button("üöÄ Ch·∫°y grid search WMA v√† l·∫•y top 10% Sharpe cho t·ª´ng m√£")

        if run_opt:
            try:
                results_list = Parallel(n_jobs=-1)(
                    delayed(optimize_wma_grid_for_ticker)(
                        tk, train_start_str, train_end_str, top_percent=0.1
                    ) for tk in usable_tickers
                )
            except Exception as e:
                # Fallback ch·∫°y tu·∫ßn t·ª± n·∫øu joblib l·ªói m√¥i tr∆∞·ªùng
                st.warning(f"Joblib Parallel g·∫∑p l·ªói ({e}), chuy·ªÉn sang ch·∫°y tu·∫ßn t·ª±.")
                results_list = [
                    optimize_wma_grid_for_ticker(tk, train_start_str, train_end_str, top_percent=0.1)
                    for tk in usable_tickers
                ]

            for tk, df_top in zip(usable_tickers, results_list):
                if df_top is not None:
                    df_temp = df_top.copy()
                    if "Sharpe Ratio" not in df_temp.columns and "Sharpe" in df_temp.columns:
                        df_temp.rename(columns={"Sharpe": "Sharpe Ratio"}, inplace=True)
                    df_temp["Ticker"] = tk
                    df_temp["MA"] = "WMA"
                    st.session_state["wma_results"][tk] = df_temp

        st.subheader("Top tham s·ªë WMA theo Sharpe (ƒë√£ l∆∞u)")
        if len(st.session_state["wma_results"]) == 0:
            st.info("Ch∆∞a c√≥ k·∫øt qu·∫£ t·ªëi ∆∞u. H√£y nh·∫•n n√∫t ch·∫°y ·ªü tr√™n.")
        else:
            for tk, df_top in st.session_state["wma_results"].items():
                st.markdown(f"### {tk}")
                st.dataframe(df_top)
                st.caption("C√°c b·ªô Short/Long n√†y s·∫Ω ƒë∆∞·ª£c ENSEMBLE ·ªü B∆∞·ªõc 4. B·∫°n KH√îNG c·∫ßn ch·ªçn tay 1 b·ªô.")


# ============= TAB 4: ENSEMBLE + BACKTEST =============
with tab4:
    st.header("B∆∞·ªõc 4. Ensemble top-K WMA, √°p lu·∫≠t th·ªã tr∆∞·ªùng VN, gh√©p danh m·ª•c v√† backtest")

    st.subheader("üìå Input t·ª´ c√°c b∆∞·ªõc tr∆∞·ªõc")
    st.write("Danh s√°ch m√£ ƒë√£ ch·ªçn:", st.session_state.selected_stocks)
    st.write("Tr·ªçng s·ªë cu·ªëi (B∆∞·ªõc 2):", st.session_state.final_weights)
    st.write("K·∫øt qu·∫£ t·ªëi ∆∞u WMA (B∆∞·ªõc 3):",
             f"{len(st.session_state['wma_results'])} m√£" if "wma_results" in st.session_state else "Ch∆∞a c√≥")

    ready = True
    if len(st.session_state.selected_stocks) == 0:
        st.warning("Thi·∫øu c·ªï phi·∫øu t·ª´ B∆∞·ªõc 1.")
        ready = False
    if len(st.session_state.final_weights) == 0:
        st.warning("Thi·∫øu tr·ªçng s·ªë t·ª´ B∆∞·ªõc 2.")
        ready = False
    if "wma_results" not in st.session_state or len(st.session_state["wma_results"]) == 0:
        st.warning("Thi·∫øu k·∫øt qu·∫£ t·ªëi ∆∞u WMA t·ª´ B∆∞·ªõc 3.")
        ready = False

    st.markdown("#### Giai ƒëo·∫°n backtest")
    st.write(f"Train: {train_start_str} ‚Üí {train_end_str}")
    st.write(f"Test:  {test_start_str} ‚Üí {test_end_str}")
    st.caption("Chi·∫øn l∆∞·ª£c ƒë∆∞·ª£c hu·∫•n luy·ªán (ch·ªçn top tham s·ªë) tr√™n TRAIN nh∆∞ng √°p d·ª•ng & ƒë√°nh gi√° Train+Test v·ªõi lu·∫≠t T+2, stop-loss,...")

    run_final = st.button("üöÄ Ch·∫°y ensemble + backtest danh m·ª•c cu·ªëi")

    if run_final and ready:
        try:
            results = build_portfolio_from_ensemble(
                wma_results_by_ticker=st.session_state["wma_results"],
                weights_by_ticker=st.session_state.final_weights,
                train_start_str=train_start_str,
                train_end_str=train_end_str,
                test_start_str=test_start_str,
                test_end_str=test_end_str,
                vote_threshold=VOTE_THRESHOLD,
                top_k=K,
                tcost_bps=tcost_bps,
                min_hold_days=MIN_HOLD_DAYS,
                stop_loss_pct=STOP_LOSS_PCT,
                cooldown_days=COOLDOWN_DAYS,
                t2_cash_days=T2_CASH_DAYS
            )

            nav_df = results["nav_df"]
            metrics_all = results["metrics_all"]
            metrics_train = results["metrics_train"]
            metrics_test = results["metrics_test"]
            eff_weights = results["eff_weights"]
            picked_debug = results["picked_rows_debug"]

            st.subheader("üìâ NAV Danh M·ª•c (Train+Test)")
            st.line_chart(nav_df["NAV"])

            st.subheader("üìä Hi·ªáu su·∫•t danh m·ª•c")
            colA, colB, colC = st.columns(3)
            colA.metric("ALL Sharpe", f"{metrics_all['Sharpe']:.2f}" if pd.notna(metrics_all['Sharpe']) else "NaN")
            colB.metric("ALL CAGR",   f"{metrics_all['CAGR']*100:.2f}%" if pd.notna(metrics_all['CAGR']) else "NaN")
            colC.metric("ALL MaxDD",  f"{metrics_all['MaxDD']*100:.2f}%" if pd.notna(metrics_all['MaxDD']) else "NaN")

            st.markdown("**Train period (in-sample):**")
            st.write(metrics_train)

            st.markdown("**Test period (out-of-sample):**")
            st.write(metrics_test)

            st.subheader("‚öñ Tr·ªçng s·ªë hi·ªáu l·ª±c sau r√†ng bu·ªôc T+2 (eff_weights)")
            st.dataframe(eff_weights.tail())

            st.subheader("üîç C√°c c·∫∑p WMA ƒë√£ ƒë∆∞·ª£c ensemble (top-K m·ªói m√£)")
            st.dataframe(picked_debug)

            csv_data = nav_df.to_csv().encode('utf-8')
            st.download_button(
                "üíæ T·∫£i NAV danh m·ª•c (CSV)",
                csv_data,
                file_name="portfolio_nav_wma_ensemble.csv",
                mime="text/csv"
            )

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói khi backtest danh m·ª•c: {e}")
    elif run_final and not ready:
        st.error("Thi·∫øu d·ªØ li·ªáu ƒë·∫ßu v√†o. H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ ch·∫°y v√† l∆∞u xong B∆∞·ªõc 1, 2, 3.")
